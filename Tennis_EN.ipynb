{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tennis Player Detection and Service Zone Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of Used Libraries\n",
    "\n",
    "This code block imports various standard and specialized libraries for video processing, object detection, and image analysis using deep learning tools.\n",
    "\n",
    "#### 1. **Python Standard Libraries**\n",
    "   - **`os` and `sys`**: These libraries provide tools for interacting with the operating system and handling environment variables, such as file paths and system configuration.\n",
    "   - **`time`**: Used to add delays in code execution, which can be useful for process synchronization or measuring execution times.\n",
    "   - **`collections.defaultdict`**: A data structure that provides a default value for keys that don't exist in a dictionary.\n",
    "   - **`math`**: Standard library for advanced mathematical calculations, such as trigonometry and algebraic functions.\n",
    "\n",
    "#### 2. **Video and Image Processing Libraries**\n",
    "   - **`cv2 (OpenCV)`**: A widely used image and video processing library. Used for capturing, modifying, and analyzing video frames, including edge detection, grayscale conversion, and result visualization.\n",
    "   - **`numpy (np)`**: Library for mathematical operations and manipulation of multi-dimensional arrays. Essential for handling image and video data in matrix form.\n",
    "   - **`moviepy.editor`**: Tool for video editing and manipulation. Facilitates combining, editing, and exporting videos.\n",
    "\n",
    "#### 3. **PyTorch Libraries**\n",
    "   - **`torch`**: PyTorch is a deep learning library used to build and run neural network models. In this case, it's used for running pre-trained models.\n",
    "   - **`torchvision.transforms`**: Provides transformations for image preprocessing, such as resizing, cropping, and normalizing images before they're input to a model.\n",
    "   - **`torchvision.models`**: Offers various pre-trained models for computer vision, such as ResNet, used in this project for keypoint detection.\n",
    "\n",
    "#### 4. **YOLO and Ultralytics Libraries**\n",
    "   - **`ultralytics.YOLO`**: YOLO (You Only Look Once) is a real-time object detection model. The Ultralytics implementation simplifies loading and using pre-trained YOLO models to detect players and objects on a tennis court.\n",
    "   - **`ultralytics.utils.plotting`**: Includes tools for annotating (drawing) on images, such as bounding boxes and coloring detected objects.\n",
    "\n",
    "#### 5. **SORT Libraries for Object Tracking**\n",
    "   - **`sort.Sort`**: SORT (Simple Online and Realtime Tracking) is an algorithm used for object tracking in videos. In this project, it's used to track players across video frames, maintaining the same player ID even if detection is temporarily lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-Step Description of the `PlayerDetection` Class\n",
    "\n",
    "#### 1. **Constructor (`__init__`)**\n",
    "   - **Purpose**: Initializes the class with the necessary parameters to process a video, detect players, and analyze if they are in the service zone.\n",
    "   - **Functionality**:\n",
    "     - Sets up the YOLO model for player detection.\n",
    "     - Initializes the SORT tracker for player tracking.\n",
    "     - Configures video input and output paths.\n",
    "     - Sets up parameters for court line detection and service zone analysis.\n",
    "\n",
    "#### 2. **Player Detection and Tracking**\n",
    "   - **Purpose**: Detect and track players in each frame of the video.\n",
    "   - **Process**:\n",
    "     - Uses YOLO to detect players in the current frame.\n",
    "     - Applies SORT to track players across frames, maintaining consistent IDs.\n",
    "     - Filters detections to only include players (class 0 in the YOLO model).\n",
    "\n",
    "#### 3. **Service Zone Analysis**\n",
    "   - **Purpose**: Determine if a player is in the service zone during a serve.\n",
    "   - **Process**:\n",
    "     - Detects the service line and other court markings.\n",
    "     - Tracks player positions relative to the service line.\n",
    "     - Flags potential foot faults if a player steps on or over the service line during a serve.\n",
    "\n",
    "#### 4. **Visualization**\n",
    "   - **Purpose**: Draw visual feedback on the video frames.\n",
    "   - **Elements Drawn**:\n",
    "     - Bounding boxes around detected players.\n",
    "     - Player IDs for tracking.\n",
    "     - Service line and other court markings.\n",
    "     - Visual indicators for service zone violations.\n",
    "\n",
    "#### 5. **Player ID Assignment**\n",
    "   - **Purpose**: Assign IDs to players based on their position on the court.\n",
    "   - **Process**:\n",
    "     - If a player is above the calculated Y threshold, they are assigned as player 1; if below, as player 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_names = [\n",
    "    \"Left-shoulder\", \"Right-shoulder\", \"Left-elbow\", \"Right-elbow\",\n",
    "    \"Left-hip\", \"Right-hip\", \"Left-knee\", \"Right-knee\", \"Left-ankle\", \"Right-ankle\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Details\n",
    "\n",
    "### Key Features\n",
    "- **Player Detection**: Uses YOLOv8 for accurate player detection.\n",
    "- **Player Tracking**: Implements SORT algorithm for consistent player tracking.\n",
    "- **Service Line Detection**: Identifies the service line for foot fault detection.\n",
    "- **Visual Feedback**: Provides real-time visualization of player tracking and service zone violations.\n",
    "- **Performance**: Optimized for real-time processing on standard hardware.\n",
    "\n",
    "### Usage\n",
    "1. Ensure all dependencies are installed.\n",
    "2. Configure the input video path in the script.\n",
    "3. Run the script to process the video.\n",
    "4. The output video will show player tracking and service zone analysis.\n",
    "\n",
    "### Dependencies\n",
    "- Python 3.8+\n",
    "- OpenCV\n",
    "- PyTorch\n",
    "- Ultralytics YOLO\n",
    "- NumPy\n",
    "- MoviePy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- [YOLOv8 Documentation](https://docs.ultralytics.com/)\n",
    "- [SORT Algorithm](https://github.com/abewley/sort)\n",
    "- [OpenCV Documentation](https://docs.opencv.org/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
